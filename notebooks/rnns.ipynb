{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "import unicodedata\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "import base64\n",
    "\n",
    "from IPython.display import Image, display\n",
    "import torch\n",
    "import numpy as np\n",
    "from jaxtyping import Int, Float\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def mm(graph: str):\n",
    "  \"\"\"for plotting mermaid.js diagrams\"\"\"\n",
    "  graphbytes = graph.encode(\"utf-8\")\n",
    "  base64_bytes = base64.b64encode(graphbytes)\n",
    "  base64_string = base64_bytes.decode(\"ascii\")\n",
    "  display(\n",
    "    Image(\n",
    "      url=\"https://mermaid.ink/img/\"\n",
    "      + base64_string\n",
    "    )\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *Recurrent Neural Network* is a function \n",
    "$$ \n",
    "\tr : \\R^p \\times \\R^m \\to \\R^o \n",
    "$$ \n",
    "where $p$ is the input dimension, $m$ is the hidden state dimension and $o$ is the output dimension. The hidden state $h_t$ depends on the previous hidden state $h_{t-1}$ and the current input $x_t$: \n",
    " \n",
    "$$ \n",
    "\tr_h(x_t, h_{t-1}) = h_t = \\sigma\\left(v(x_t) + q(h_{t-1}) \\right) \n",
    "\t\\qquad  \n",
    "\t\\hat{y} = u(h_t) \n",
    "$$ \n",
    " \n",
    "Where  \n",
    "- $v: \\R^p \\to \\R^m$ is the embedding/input function \n",
    "- $q: \\R^m \\to \\R^m$ is the recurrent function \n",
    "- $u: \\R^m \\to \\R^o$ is the unembedding/output function \n",
    " \n",
    "In the simplest case, $u,q,v$ are all affine maps, but they can be arbitrarily complicated functions. \n",
    " \n",
    "$r$ can be induced into a sequence-to-sequence map: \n",
    " \n",
    "given some sequence $X = [x_1, x_2, \\ldots x_n]$, we define an initial state $h_0$ (this can be zero, random, or learned) and first compute the hidden states: \n",
    " \n",
    "$$ \n",
    "\t[r_h(X)]_i = \\begin{bmatrix}  \n",
    "\t\t\\sigma\\left(v(x_1) + q(h_0) \\right) \\\\ \n",
    "\t\t\\sigma\\left(v(x_2) + q(h_1) \\right) \\\\ \n",
    "\t\t\\vdots \\\\ \n",
    "\t\\end{bmatrix} \n",
    "$$ \n",
    " \n",
    "and then we project each hidden state onto the output space: \n",
    "$$ \n",
    "\t[r_u(X)]_i = \\begin{bmatrix}  \n",
    "\t\tu(h_1) \\\\ \n",
    "\t\tu(h_2) \\\\ \n",
    "\t\t\\vdots \\\\ \n",
    "\t\\end{bmatrix} \n",
    "$$ \n",
    " \n",
    "Note that while the output projections can all be done in parallel, or the output projection $u(h_{i})$ parallel with $r_h(x_{i+1}, h_{i})$, the recurrent function $q$ must be computed sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmdyYXBoIExSOwogICAgeDEoKCJ44oKBIikpCiAgICB4ZGQoKCIuLi4iKSkKICAgIHh0bTEoKCJ44oKc4oKL4oKBIikpCiAgICB4dCgoInjigpwiKSkKICAgIAogICAgaDFbWyJo4oKBIl1dCiAgICBoZGRbWyIuLi4iXV0KICAgIGh0bTFbWyJo4oKc4oKL4oKBIl1dCiAgICBodFtbImjigpwiXV0KICAgIAogICAgeTEoKCJ54oKBIikpCiAgICB5ZGQoKCIuLi4iKSkKICAgIHl0bTEoKCJ54oKc4oKL4oKBIikpCiAgICB5dCgoInnigpwiKSkKICAgIAogICAgeDEtLSAidih44oKBKSIgLS0+aDEKICAgIGgxLS0gInEoaOKCgSkiIC0tPmhkZAogICAgeGRkLS0gInYoLi4uKSIgLS0+aGRkCiAgICBoZGQtLSAicSguLi4pIiAtLT5odG0xCiAgICB4dG0xLS0gInYoeOKCnOKCi+KCgSkiIC0tPmh0bTEKICAgIGh0bTEtLSAicSho4oKc4oKL4oKBKSIgLS0+aHQKICAgIHh0LS0gInYoeOKCnCkiIC0tPmh0CiAgICAKICAgIGgxLS0gInUoaOKCgSkiIC0tPnkxCiAgICBoZGQtLSAidSguLi4pIiAtLT55ZGQKICAgIGh0bTEtLSAidSho4oKc4oKL4oKBKSIgLS0+eXRtMQogICAgaHQtLSAidSho4oKcKSIgLS0+eXQK\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mm(\"\"\"\n",
    "graph LR;\n",
    "    x1((\"x₁\"))\n",
    "    xdd((\"...\"))\n",
    "    xtm1((\"xₜ₋₁\"))\n",
    "    xt((\"xₜ\"))\n",
    "    \n",
    "    h1[[\"h₁\"]]\n",
    "    hdd[[\"...\"]]\n",
    "    htm1[[\"hₜ₋₁\"]]\n",
    "    ht[[\"hₜ\"]]\n",
    "    \n",
    "    y1((\"y₁\"))\n",
    "    ydd((\"...\"))\n",
    "    ytm1((\"yₜ₋₁\"))\n",
    "    yt((\"yₜ\"))\n",
    "    \n",
    "    x1-- \"v(x₁)\" -->h1\n",
    "    h1-- \"q(h₁)\" -->hdd\n",
    "    xdd-- \"v(...)\" -->hdd\n",
    "    hdd-- \"q(...)\" -->htm1\n",
    "    xtm1-- \"v(xₜ₋₁)\" -->htm1\n",
    "    htm1-- \"q(hₜ₋₁)\" -->ht\n",
    "    xt-- \"v(xₜ)\" -->ht\n",
    "    \n",
    "    h1-- \"u(h₁)\" -->y1\n",
    "    hdd-- \"u(...)\" -->ydd\n",
    "    htm1-- \"u(hₜ₋₁)\" -->ytm1\n",
    "    ht-- \"u(hₜ)\" -->yt\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from typing import List\n",
    "\n",
    "# Defining the BasicRNN class\n",
    "class BasicRNN(nn.Module):\n",
    "    def __init__(self, dim_input: int, dim_hidden: int, dim_output: int):\n",
    "        super(BasicRNN, self).__init__()\n",
    "        # TODO\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            x: Float[torch.Tensor, \"seq_len dim_input\"],\n",
    "        ) -> Float[torch.Tensor, \"seq_len dim_output\"]:\n",
    "        # TODO\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
